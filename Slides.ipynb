{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HPC for All\n",
    "\n",
    "Ana Gainaru <br/>\n",
    "<small>Vanderbilt University</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me\n",
    "\n",
    "<cite> www.ana-gainaru.com (anagainaru Github) </cite>\n",
    "\n",
    "<img src=\"figures/aboutme.png\" width=\"200\" align=\"left\" />\n",
    "\n",
    "<br />\n",
    "PhD in Computer Science <br />\n",
    "<small> Failure prediction, Hybrid checkpointing <br />\n",
    "        Fault tolerance framework for Blue Waters </small>\n",
    "\n",
    "<br /><br />\n",
    "HPC Architect <br />\n",
    "<small> Collective communication <br />\n",
    "         HW custom application optimization</small>\n",
    "\n",
    "<br />\n",
    "Research Assistant Professor <br />\n",
    "<small>Scheduling <br />\n",
    "            Heterogeneous, dynamic applications</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About HPC\n",
    "\n",
    "![HPC systems](figures/hpc.png)\n",
    "\n",
    "HPC system evolve together with large monolithic codes\n",
    " - Focus on performance\n",
    " - Developed by the community for years\n",
    " - Tuned to scale and run on large-scale infrastructures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# HPC Evolution\n",
    "\n",
    "![HPC systems](figures/hpc.png)\n",
    "\n",
    "- NUMA\n",
    "- Hardware threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Accelerators, Memory hierarchy \n",
    "- High-bandwidth memory\n",
    "- Burst buffers, Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<cite> Summit/Sierra: NVLink, NVMe, NVSwitch, GPUDirect, Unified Virtual Memory </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# HPC Evolution\n",
    "\n",
    "![HPC systems](figures/hpc.png)\n",
    "\n",
    "**Unknowns to come**\n",
    " - Chiplet architectures\n",
    " - Configurable Spatial Accelerator architecture\n",
    " - Computing on switch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# HPC Evolution\n",
    "\n",
    "Top500 June 2018 <br/>\n",
    "<small> Only 55 systems that have both HPL and HPCG information </small>\n",
    "\n",
    "\n",
    "<img src=\"figures/hpcg_hpl.png\" width=\"600\" />\n",
    "\n",
    "<cite> Two orders of magnitude performance gap </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# XSEDE\n",
    "\n",
    "<img src=\"figures/cumulative_walltime.png\"  width=\"350\" align=\"right\" valigh=\"top\" />\n",
    "\n",
    "Workloads running on Stempede (representative of all XSEDE systems)\n",
    "\n",
    "```\n",
    "Applications running on one node: 33%\n",
    "Applications running on < 10 nodes: 79%\n",
    "Applications running on < 100 nodes: 98%\n",
    "Average number of nodes: 15 (max 10,417)\n",
    "```\n",
    "\n",
    "<br/><br/>\n",
    "Applications run between a few minutes and over 100 hours \n",
    "<br/>\n",
    "\n",
    "<cite> Small jobs are distributed almost uniformly throughout the year </cite>\n",
    "\n",
    "<small> Over 80% of the days run multiple small jobs (average volume of 100 node hours) </small>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Second generation applications\n",
    "\n",
    "![Variability](figures/app_variability.png)\n",
    "\n",
    "Variability in execution time and memory usage <br/><br/>\n",
    "<small>\n",
    "(a) Variability factor (ratio between maximum variability over execution time) for MultiAtlas, a second generation application (blue) and a traditional application that ran on the Mira supercomputer (orange) <br/><br />\n",
    "(b) Memory usage variability within multiple phases of the MultiAtlas code\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Performance variability\n",
    "\n",
    "<img src=\"figures/correlation.png\"  width=\"300\" align=\"right\" valigh=\"top\" />\n",
    "          \n",
    "1. Intrinsic to the code\n",
    "2. Dependent on the input data \n",
    "    - size or characteristics\n",
    "3. Due to system failures\n",
    "4. Due to resource contention\n",
    "5. Due to other runtime decisions\n",
    "    - scheduling policies\n",
    "\n",
    "**Same input data and execution parameters**\n",
    "- Task based GEMM has 20% variation on CPU (over 50% on GPUs)\n",
    "- Multi Atlas has over 10x variation when running on one node (around 7% intrinsic to the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Research Statement\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "Directions:\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "At system, middleware, application levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "![Congestion](figures/intrepid_congestion.png)\n",
    "\n",
    "`Congestion caused by sharing resource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Research Statement\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "Directions:\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "- At system, middleware, application levels\n",
    "\n",
    "![Resiliency](figures/resiliency.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Research Statement\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "Directions:\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "- At system, middleware, application levels\n",
    "\n",
    "![Scheduling](figures/wait_time.png)\n",
    "<small> Queue wait time is a function of the requested walltime, requested cores, platform occupancy, and platform policy </small>\n",
    "\n",
    "<sub> K. Yamamoto et al., “The K computer Operations: Experiences and\n",
    "Statistics”, Elsevier Computer Science, Volume 29, 2014, Pages 576-585 </sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Research Statement\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "Directions:\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "- At system, middleware, application levels\n",
    "\n",
    "<img src=\"figures/multiatlas_corr.png\" width=\"300\" align=\"left\" />\n",
    "<img src=\"figures/multiatlas_prediction.png\" width=\"390\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Research Statement\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "Directions:\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "- At system, middleware, application levels\n",
    "\n",
    "**(2) Design new middleware to adapt to the needs of unpredictable applications**\n",
    "- On-going work in I/O, scheduling and fault tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/sch.png\" width=\"250\" align=\"right\" />\n",
    "\n",
    "# Preliminary results\n",
    "\n",
    "## Scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Direction 1**: Optimize the way emerging applications use current scheduling systems\n",
    " - Automating the resorce estimation provided by users \n",
    " - Using checkpointing strategies to deal with applications being killed by the runtime `INRIA`\n",
    " - Developing tools to understand task based scheduling limitations `UTK`\n",
    "\n",
    "**Direction 2**: Modernize existing schedulers to become more flexible \n",
    " - Provide flexible resource management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Resource estimation\n",
    "\n",
    "<img src=\"figures/estimates1.png\" width=\"400\" align=\"left\" />\n",
    "<img src=\"figures/estimates2.png\" width=\"380\" />\n",
    "\n",
    "Use logs of execution to predict future runs\n",
    " - Fit the CDF with polynomial/distribution interpolation\n",
    " - Machine learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Resource estimation\n",
    "\n",
    "<img src=\"figures/sequence.png\" width=\"400\" align=\"left\" valign=\"top\" />\n",
    "<img src=\"figures/intrepid_utilization.png\" width=\"250\" />\n",
    "\n",
    "<br/>\n",
    "\n",
    "Use logs of execution to predict future runs\n",
    " - **Fit the CDF with polynomial/distribution interpolation**\n",
    " - Machine learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Resource estimation\n",
    "\n",
    "Productivity is more important then performance\n",
    " - Codes change depending on each study\n",
    " - Modules are combined in different ways\n",
    " \n",
    "<img src=\"figures/history.png\" width=\"450\" />\n",
    " \n",
    " <cite> Discard distant future and only keep the last week/month for the prediction </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Implementation\n",
    "\n",
    "Machine learning to identify amount of history\n",
    " - Based on how frequent an application is ran\n",
    " - Based on how frequent the application changes behavior\n",
    " \n",
    "**(1) Use the generated sequences to submit an application on Slurm**\n",
    " - Slurm doesn't automatically re-submit application in case of a failure\n",
    " \n",
    "**(2) Reserve a \"Job Lane\" for multiple jobs**\n",
    " - Use the generated sequences to schedule jobs inside the Lane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Preliminary resutls\n",
    "## Scheduling\n",
    "\n",
    "Direction 1: Optimize the way emerging applications use current scheduling systems\n",
    " - Automating the resorce estimation provided by users \n",
    " - Using checkpointing strategies to deal with applications being killed by the runtime\n",
    " - Developing tools to understand task based scheduling limitations \n",
    "\n",
    "**Direction 2: Modernize existing schedulers to become more flexible **\n",
    " - **Provide flexible resource management**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Flexible resource management\n",
    "\n",
    "## Move towards online schedulers\n",
    "Oneline schedulers work perfect with neuroscience workloads\n",
    " - Not necessary with classic HPC\n",
    "\n",
    "<img src=\"figures/scheduling.png\" alt=\"Hybrid schedulers\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Very preliminary results\n",
    "\n",
    "Simulating hybrid schedulers (stochastic batch scheduler)\n",
    "\n",
    "<img src=\"figures/scheduling_result.png\" width=\"500\" />\n",
    "\n",
    "<cite> Variability factor = ratio between maximum variability over execution time </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Code\n",
    "\n",
    "Code that is returning the sequence of request used by Vanderbilt: <br />\n",
    "https://github.com/anagainaru/HPCWalltime\n",
    "\n",
    "<small> Speculative Scheduling Techniques for Stochastic HPC Applications <br />\n",
    "[ICPP 2019] </small>\n",
    "\n",
    "<small> Making Speculative Scheduling Robust to Incomplete Data <br />\n",
    "[SCALA@SC 2019] </small>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/anagainaru/ScheduleFlow/master/docs/logo.png\" alt=\"ScheduleFlow\" width=\"200\" align=\"left\" />\n",
    "\n",
    "<br/><br/>\n",
    "Simulator for batch schedulers:  <br />\n",
    "https://github.com/anagainaru/ScheduleFlow\n",
    "\n",
    "<small> On-the-fly scheduling vs. reservation-based scheduling for unpredictable workflows  <br />\n",
    "[IJHPCA 2019] </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"figures/ft.png\" width=\"250\" align=\"right\" />\n",
    "\n",
    "# Preliminary results\n",
    "\n",
    "## Fault tolerance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Direction 1:** Characterizing the Intrinsic Application Resiliency to Failures\n",
    " - Machine Learning Systems\n",
    " - PDE-based simulations\n",
    " - Second generation applications\n",
    " \n",
    "**Direction 2:** Adapt current checkpointing/replication methods\n",
    " - Application-Level Fault Tolerance \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# PDE-Based Simulations\n",
    "\n",
    "E.g. Two-dimensional heat flow problem\n",
    "\n",
    "<img src=\"figures/spmv_error.png\" width=\"300\" align=\"right\" valign=\"middle\" />\n",
    "<img src=\"figures/heat_equation.png\" width=\"400\" />\n",
    "\n",
    "Translates to a series of SpMV that can propagate errors and degrade performance\n",
    "\n",
    "### Failures can degrade the performance or prevent convergency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Characterize intrinsic resilient behavior\n",
    "\n",
    "We define a metric to characterize the rate of change within each component u_i of the solution vector\n",
    " - that corresponds to the point (x_i , y_i) in the spatial domain\n",
    " \n",
    "**First resiliency gradient**\n",
    "![Metric](figures/metric.png)\n",
    "\n",
    "Similarly, we can define the **Second resiliency gradient**\n",
    " - characterize the change in acceleration\n",
    "\n",
    "![Metric](figures/metric2.png)\n",
    "\n",
    "<cite> We define slow and fast changing elements </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Failure injection\n",
    "\n",
    "Resiliency properties when injecting failures in the slow and fast changing components of the solution vector\n",
    "\n",
    "![Injection](figures/spMV_injection.png)\n",
    "\n",
    "<small> (a) Relative increase in the number of iterations to convergence compared to error-free execution</small>\n",
    "\n",
    "<small> (b) Histogram of the scale of relative error in the solution vector compared to the convergent vector in\n",
    "error-free execution </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Resiliency metrics in space\n",
    "\n",
    "Similar to time but based on neighbor values\n",
    "\n",
    "<img alt=\"Space metric\" src=\"figures/patch_space.png\" width=\"400\"/>\n",
    "\n",
    "Classifying the spatial domain into patches based on the space chainging metric\n",
    " - First or second gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Small and constant values\n",
    "\n",
    "Can be interpolated \n",
    " - based on previous value (in time)\n",
    " - based on the average neighbor values\n",
    " \n",
    "![Interpolation](figures/constant.png)\n",
    "\n",
    "<small> Percentage of elements in the solution vector that either remain constants through iterations or have small resiliency gradients that allow for an error to be smoothed out by interpolation </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Time-space change rate\n",
    "\n",
    "The evolution of \"patches\" in the spatial domain over time for the heat-flow problem\n",
    "![time space](figures/patch_time.png)\n",
    "\n",
    "Protect only border elements (or with stronger methods)\n",
    "\n",
    "### How often to trigger a new characterization phase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Preliminary results\n",
    "\n",
    "<img src=\"figures/interpolation.png\" width=\"450\" />\n",
    "\n",
    "<small> Relative performance degradation compared to failure-free execution when injecting failures in the high gradient elements or in low-gradient elements (with or without interpolation) </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Code\n",
    "\n",
    "University of Florida Sparse Matrix Collection: <br/>\n",
    "https://www.cise.ufl.edu/research/sparse/matrices/list_by_id.html\n",
    "\n",
    "<img src=\"figures/matrix.gif\" align=\"right\" width=\"200\" />\n",
    "\n",
    "Code for SpMV <br/>\n",
    "https://github.com/vanderbiltscl/spMV_customFI\n",
    "\n",
    "<cite> Preliminary work, not all the code is available </cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Future\n",
    "\n",
    "<cite> Update the HPC software stack for the new generation of applications </cite>\n",
    "\n",
    "**(1) Understand performance variability**\n",
    "- Scheduling decisions (bach and task schedulers)\n",
    "- Caused by fault tolerance mechanisms\n",
    "- I/O congestion (conected with fault tolerance and scheduling)\n",
    "\n",
    "**(2) Design new middleware to adapt to the needs of unpredictable applications**\n",
    "- Promote communication between the application and the middleware\n",
    "- Application aware fault tolerance\n",
    "- Hybrid / speculative schedulers that informs the application "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"https://avatars2.githubusercontent.com/u/49881432?s=200&v=4\" alt=\"Vanerbilt\" align=\"right\" width=\"150\" />\n",
    "<img src=\"https://anagainaru.github.io/assets/images/favicon.png\" alt=\"Ana Gainaru\" align=\"right\" width=\"150\" />\n",
    "\n",
    "# Thank you\n",
    "\n",
    "<br />\n",
    "\n",
    "### Questions?\n",
    "\n",
    "<br /><br />\n",
    "\n",
    "<cite> ana.gainaru@vanderbilt.edu </cite> \n",
    "\n",
    "http://www.ana-gainaru.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
